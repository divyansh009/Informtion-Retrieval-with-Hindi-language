{"cells":[{"cell_type":"code","execution_count":null,"metadata":{"id":"wQ84G80YKtNt"},"outputs":[],"source":["import pandas as pd\n","import numpy as np\n","\n","import torch\n","from torch.utils.data import Dataset, DataLoader \n","\n","import warnings\n","warnings.filterwarnings('ignore')\n","\n","import torch\n","from torch import cuda\n","import torch.nn as nn\n","\n","from sklearn.metrics import classification_report\n","from sklearn.model_selection import train_test_split\n","\n","import transformers as t\n","from transformers import AutoModel\n","\n","import re\n","import string"]},{"cell_type":"code","source":["!pip install transformers seqeval[gpu] sentencepiece"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"9rGimehvLZ0-","outputId":"fb09f428-c709-44c5-84f7-e91f732ae7ce"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Requirement already satisfied: transformers in /usr/local/lib/python3.7/dist-packages (4.18.0)\n","Requirement already satisfied: seqeval[gpu] in /usr/local/lib/python3.7/dist-packages (1.2.2)\n","Requirement already satisfied: sentencepiece in /usr/local/lib/python3.7/dist-packages (0.1.96)\n","Requirement already satisfied: sacremoses in /usr/local/lib/python3.7/dist-packages (from transformers) (0.0.49)\n","Requirement already satisfied: importlib-metadata in /usr/local/lib/python3.7/dist-packages (from transformers) (4.11.3)\n","Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.7/dist-packages (from transformers) (6.0)\n","Requirement already satisfied: requests in /usr/local/lib/python3.7/dist-packages (from transformers) (2.23.0)\n","Requirement already satisfied: tokenizers!=0.11.3,<0.13,>=0.11.1 in /usr/local/lib/python3.7/dist-packages (from transformers) (0.11.6)\n","Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.7/dist-packages (from transformers) (1.21.5)\n","Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.7/dist-packages (from transformers) (21.3)\n","Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.7/dist-packages (from transformers) (4.63.0)\n","Requirement already satisfied: filelock in /usr/local/lib/python3.7/dist-packages (from transformers) (3.6.0)\n","Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.7/dist-packages (from transformers) (2019.12.20)\n","Requirement already satisfied: huggingface-hub<1.0,>=0.1.0 in /usr/local/lib/python3.7/dist-packages (from transformers) (0.5.1)\n","Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.7/dist-packages (from huggingface-hub<1.0,>=0.1.0->transformers) (3.10.0.2)\n","Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from packaging>=20.0->transformers) (3.0.7)\n","Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata->transformers) (3.7.0)\n","Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (1.24.3)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (2021.10.8)\n","Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (2.10)\n","Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (3.0.4)\n","Requirement already satisfied: six in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers) (1.15.0)\n","Requirement already satisfied: joblib in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers) (1.1.0)\n","Requirement already satisfied: click in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers) (7.1.2)\n","Requirement already satisfied: scikit-learn>=0.21.3 in /usr/local/lib/python3.7/dist-packages (from seqeval[gpu]) (1.0.2)\n","Requirement already satisfied: scipy>=1.1.0 in /usr/local/lib/python3.7/dist-packages (from scikit-learn>=0.21.3->seqeval[gpu]) (1.4.1)\n","Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.7/dist-packages (from scikit-learn>=0.21.3->seqeval[gpu]) (3.1.0)\n"]}]},{"cell_type":"code","source":["def get_string_punctuations():\n","  ans = re.escape(string.punctuation)\n","  return ans\n","punctuations = get_string_punctuations()"],"metadata":{"id":"iHRXs_zzJpit"},"execution_count":null,"outputs":[]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"X2OgyEMwKyAd","outputId":"6b403fdd-e6eb-4e53-9828-41b273382aca"},"outputs":[{"output_type":"stream","name":"stdout","text":["Mounted at /content/drive\n"]}],"source":["from google.colab import drive\n","drive.mount('/content/drive')"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":419},"id":"TkCWrB45KrJH","outputId":"cf3599f5-e2e0-4ef2-9c68-0b4e63bd81c4"},"outputs":[{"output_type":"execute_result","data":{"text/plain":["                                                     word  iob_tag\n","0       # id fb77da5d-c4e6-4545-ac07-600a7ff04920\\tdom...     None\n","1                                            जियोर्जियोन         O\n","2                                                   ०१९।         O\n","3                                                 जेपीजी         O\n","4                                                      |         O\n","...                                                   ...      ...\n","259861                                          क्वालकॉम    B-PROD\n","259862                                       स्नैपड्रैगन    I-PROD\n","259863                                                 .         O\n","259864                                                के         O\n","259865                                            उदाहरण         O\n","\n","[259866 rows x 2 columns]"],"text/html":["\n","  <div id=\"df-4720ddd2-9da8-4342-9e6e-ed06d03eb54c\">\n","    <div class=\"colab-df-container\">\n","      <div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>word</th>\n","      <th>iob_tag</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td># id fb77da5d-c4e6-4545-ac07-600a7ff04920\\tdom...</td>\n","      <td>None</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>जियोर्जियोन</td>\n","      <td>O</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>०१९।</td>\n","      <td>O</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>जेपीजी</td>\n","      <td>O</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>|</td>\n","      <td>O</td>\n","    </tr>\n","    <tr>\n","      <th>...</th>\n","      <td>...</td>\n","      <td>...</td>\n","    </tr>\n","    <tr>\n","      <th>259861</th>\n","      <td>क्वालकॉम</td>\n","      <td>B-PROD</td>\n","    </tr>\n","    <tr>\n","      <th>259862</th>\n","      <td>स्नैपड्रैगन</td>\n","      <td>I-PROD</td>\n","    </tr>\n","    <tr>\n","      <th>259863</th>\n","      <td>.</td>\n","      <td>O</td>\n","    </tr>\n","    <tr>\n","      <th>259864</th>\n","      <td>के</td>\n","      <td>O</td>\n","    </tr>\n","    <tr>\n","      <th>259865</th>\n","      <td>उदाहरण</td>\n","      <td>O</td>\n","    </tr>\n","  </tbody>\n","</table>\n","<p>259866 rows × 2 columns</p>\n","</div>\n","      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-4720ddd2-9da8-4342-9e6e-ed06d03eb54c')\"\n","              title=\"Convert this dataframe to an interactive table.\"\n","              style=\"display:none;\">\n","        \n","  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n","       width=\"24px\">\n","    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n","    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n","  </svg>\n","      </button>\n","      \n","  <style>\n","    .colab-df-container {\n","      display:flex;\n","      flex-wrap:wrap;\n","      gap: 12px;\n","    }\n","\n","    .colab-df-convert {\n","      background-color: #E8F0FE;\n","      border: none;\n","      border-radius: 50%;\n","      cursor: pointer;\n","      display: none;\n","      fill: #1967D2;\n","      height: 32px;\n","      padding: 0 0 0 0;\n","      width: 32px;\n","    }\n","\n","    .colab-df-convert:hover {\n","      background-color: #E2EBFA;\n","      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n","      fill: #174EA6;\n","    }\n","\n","    [theme=dark] .colab-df-convert {\n","      background-color: #3B4455;\n","      fill: #D2E3FC;\n","    }\n","\n","    [theme=dark] .colab-df-convert:hover {\n","      background-color: #434B5C;\n","      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n","      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n","      fill: #FFFFFF;\n","    }\n","  </style>\n","\n","      <script>\n","        const buttonEl =\n","          document.querySelector('#df-4720ddd2-9da8-4342-9e6e-ed06d03eb54c button.colab-df-convert');\n","        buttonEl.style.display =\n","          google.colab.kernel.accessAllowed ? 'block' : 'none';\n","\n","        async function convertToInteractive(key) {\n","          const element = document.querySelector('#df-4720ddd2-9da8-4342-9e6e-ed06d03eb54c');\n","          const dataTable =\n","            await google.colab.kernel.invokeFunction('convertToInteractive',\n","                                                     [key], {});\n","          if (!dataTable) return;\n","\n","          const docLinkHtml = 'Like what you see? Visit the ' +\n","            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n","            + ' to learn more about interactive tables.';\n","          element.innerHTML = '';\n","          dataTable['output_type'] = 'display_data';\n","          await google.colab.output.renderOutput(dataTable, element);\n","          const docLink = document.createElement('div');\n","          docLink.innerHTML = docLinkHtml;\n","          element.appendChild(docLink);\n","        }\n","      </script>\n","    </div>\n","  </div>\n","  "]},"metadata":{},"execution_count":3}],"source":["import pandas as pd\n","df = pd.read_csv(\"drive/MyDrive/hi_train.conll\", names = ['word', 'iob_tag'],sep = '_ _',engine = 'python')\n","# df.\n","df"]},{"cell_type":"code","source":["def preprocess_train(file_path):\n","    test = []\n","    temp = []\n","    j = 0\n","    vec = []\n","    with open(file_path, encoding = 'utf-8') as f:\n","        data = f.readlines()\n","    vec = data \n","\n","    for i in range(len(vec)):\n","        if '#' not in vec[i]:\n","            temp.append(vec[i])\n","\n","\n","    temp = [w.replace('\\n', '') for w in temp]\n","    res = [list(sub) for ele, sub in groupby(temp, key = bool) if ele]\n","    for i in range(len(res)):\n","        string = ''\n","        labels = ''\n","        for j in range(len(res[i])):\n","            temp = []\n","            temp.append(res[i][j].split(' _ _ '))\n","            if not string:\n","                string = string +  temp[0][0]\n","            else:\n","                string = string + ' ' + temp[0][0]\n","            if not labels:\n","                labels = labels + temp[0][1]\n","            else:\n","                labels = labels + ',' + temp[0][1]\n","            \n","        test.append([string,labels])\n","    return test\n","\n","file_path = \"hi_train.conll\"\n","dataset =  preprocessing(file_path)"],"metadata":{"id":"O9ULiUxDiQ4U"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["df = preprocess_train(df)"],"metadata":{"id":"sVRT8sDAjay3"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["df"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":419},"id":"Q_54vESwjyb1","outputId":"8bc7ec04-79de-4ca1-dc24-c0e16d4550e1"},"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["              word iob_tag\n","0      जियोर्जियोन       O\n","1             ०१९।       O\n","2           जेपीजी       O\n","3                        O\n","4             आंधी    B-CW\n","...            ...     ...\n","33807          चाय   B-GRP\n","33808       अंकुरण  B-PROD\n","33809        रीजनल  I-CORP\n","33810     क्वालकॉम  B-PROD\n","33811  स्नैपड्रैगन  I-PROD\n","\n","[33812 rows x 2 columns]"],"text/html":["\n","  <div id=\"df-f70ae4d6-ac75-4ceb-9f85-6e69efeceb91\">\n","    <div class=\"colab-df-container\">\n","      <div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>word</th>\n","      <th>iob_tag</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>जियोर्जियोन</td>\n","      <td>O</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>०१९।</td>\n","      <td>O</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>जेपीजी</td>\n","      <td>O</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td></td>\n","      <td>O</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>आंधी</td>\n","      <td>B-CW</td>\n","    </tr>\n","    <tr>\n","      <th>...</th>\n","      <td>...</td>\n","      <td>...</td>\n","    </tr>\n","    <tr>\n","      <th>33807</th>\n","      <td>चाय</td>\n","      <td>B-GRP</td>\n","    </tr>\n","    <tr>\n","      <th>33808</th>\n","      <td>अंकुरण</td>\n","      <td>B-PROD</td>\n","    </tr>\n","    <tr>\n","      <th>33809</th>\n","      <td>रीजनल</td>\n","      <td>I-CORP</td>\n","    </tr>\n","    <tr>\n","      <th>33810</th>\n","      <td>क्वालकॉम</td>\n","      <td>B-PROD</td>\n","    </tr>\n","    <tr>\n","      <th>33811</th>\n","      <td>स्नैपड्रैगन</td>\n","      <td>I-PROD</td>\n","    </tr>\n","  </tbody>\n","</table>\n","<p>33812 rows × 2 columns</p>\n","</div>\n","      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-f70ae4d6-ac75-4ceb-9f85-6e69efeceb91')\"\n","              title=\"Convert this dataframe to an interactive table.\"\n","              style=\"display:none;\">\n","        \n","  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n","       width=\"24px\">\n","    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n","    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n","  </svg>\n","      </button>\n","      \n","  <style>\n","    .colab-df-container {\n","      display:flex;\n","      flex-wrap:wrap;\n","      gap: 12px;\n","    }\n","\n","    .colab-df-convert {\n","      background-color: #E8F0FE;\n","      border: none;\n","      border-radius: 50%;\n","      cursor: pointer;\n","      display: none;\n","      fill: #1967D2;\n","      height: 32px;\n","      padding: 0 0 0 0;\n","      width: 32px;\n","    }\n","\n","    .colab-df-convert:hover {\n","      background-color: #E2EBFA;\n","      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n","      fill: #174EA6;\n","    }\n","\n","    [theme=dark] .colab-df-convert {\n","      background-color: #3B4455;\n","      fill: #D2E3FC;\n","    }\n","\n","    [theme=dark] .colab-df-convert:hover {\n","      background-color: #434B5C;\n","      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n","      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n","      fill: #FFFFFF;\n","    }\n","  </style>\n","\n","      <script>\n","        const buttonEl =\n","          document.querySelector('#df-f70ae4d6-ac75-4ceb-9f85-6e69efeceb91 button.colab-df-convert');\n","        buttonEl.style.display =\n","          google.colab.kernel.accessAllowed ? 'block' : 'none';\n","\n","        async function convertToInteractive(key) {\n","          const element = document.querySelector('#df-f70ae4d6-ac75-4ceb-9f85-6e69efeceb91');\n","          const dataTable =\n","            await google.colab.kernel.invokeFunction('convertToInteractive',\n","                                                     [key], {});\n","          if (!dataTable) return;\n","\n","          const docLinkHtml = 'Like what you see? Visit the ' +\n","            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n","            + ' to learn more about interactive tables.';\n","          element.innerHTML = '';\n","          dataTable['output_type'] = 'display_data';\n","          await google.colab.output.renderOutput(dataTable, element);\n","          const docLink = document.createElement('div');\n","          docLink.innerHTML = docLinkHtml;\n","          element.appendChild(docLink);\n","        }\n","      </script>\n","    </div>\n","  </div>\n","  "]},"metadata":{},"execution_count":10}]},{"cell_type":"markdown","source":["## Initializing values to global variables"],"metadata":{"id":"tmgzdIALkYNn"}},{"cell_type":"code","execution_count":null,"metadata":{"id":"3CP9cTgm3LVr"},"outputs":[],"source":["LEARNING_RATE = 1e-03\n","MAX_GRAD_NORM = 10\n","TRAIN_BATCH_SIZE = 4\n","MAX_LEN = 30\n","VALID_BATCH_SIZE = 2\n","EPOCHS = 1"]},{"cell_type":"markdown","source":["## Import BERT Tokenizer from ai4bharat"],"metadata":{"id":"dqPC91aKlzvi"}},{"cell_type":"code","execution_count":null,"metadata":{"id":"-yOCJDIGngbm","colab":{"base_uri":"https://localhost:8080/","height":371,"referenced_widgets":["3bbc3477d289400d919ba3049ba9dc63","b2fe9ed77ebb48e6beac70d7f29507d2","8d4f50b54f9142ddb9596519cb0acb15","8f315c9831f944f3a6e275e204f81bd9","a11bbcbf9dd0457799e3b8fc419bc03c","4be9926eae1740c6a60b589b49303927","e24d75c7e7c048b88498cb583cd511c0","8b4510d705794fc39927d720ebf423d8","f0dd4182cb214191a6c88144c7e7945e","ec5eb972a4a24c76919ccc3ff5861896","5cdde97f31e5433f856b0d6b189e4be2","f9b986f2adf84a51b6d5160f17245727","6e20a482debf4e81b66a3b9694d013f1","c7e97513a7874c1b9618d2758311ce8c","cbce898eabfe49b2af0b59052f01f7c9","2c11a22d099d434cb99c4ef978ea3a71","3de465594e5c47f9ad3a452e574e3e27","367d4b5c974c4931b44d7d94aa35b109","3f2ff6b220994ebcaf899f462d23ea9b","8db8002e2c6a4d198dfadb81d6c371b1","4833c1f06a2848f7a95f3b861f3f2a1e","c20623f149da446a9359633925ca9ef9"]},"outputId":"adb681bf-23fa-4d5d-f816-d103ce40389f"},"outputs":[{"output_type":"display_data","data":{"text/plain":["Downloading:   0%|          | 0.00/507 [00:00<?, ?B/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"3bbc3477d289400d919ba3049ba9dc63"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["Downloading:   0%|          | 0.00/5.38M [00:00<?, ?B/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"f9b986f2adf84a51b6d5160f17245727"}},"metadata":{}},{"output_type":"error","ename":"KeyboardInterrupt","evalue":"ignored","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)","\u001b[0;32m<ipython-input-12-e0907b75f12f>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mtokenizer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mAutoTokenizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfrom_pretrained\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'ai4bharat/indic-bert'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/transformers/models/auto/tokenization_auto.py\u001b[0m in \u001b[0;36mfrom_pretrained\u001b[0;34m(cls, pretrained_model_name_or_path, *inputs, **kwargs)\u001b[0m\n\u001b[1;32m    544\u001b[0m             \u001b[0mtokenizer_class_py\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtokenizer_class_fast\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mTOKENIZER_MAPPING\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mtype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mconfig\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    545\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mtokenizer_class_fast\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0muse_fast\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mtokenizer_class_py\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 546\u001b[0;31m                 \u001b[0;32mreturn\u001b[0m \u001b[0mtokenizer_class_fast\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfrom_pretrained\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpretrained_model_name_or_path\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    547\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    548\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0mtokenizer_class_py\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/transformers/tokenization_utils_base.py\u001b[0m in \u001b[0;36mfrom_pretrained\u001b[0;34m(cls, pretrained_model_name_or_path, *init_inputs, **kwargs)\u001b[0m\n\u001b[1;32m   1785\u001b[0m             \u001b[0muse_auth_token\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0muse_auth_token\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1786\u001b[0m             \u001b[0mcache_dir\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcache_dir\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1787\u001b[0;31m             \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1788\u001b[0m         )\n\u001b[1;32m   1789\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/transformers/tokenization_utils_base.py\u001b[0m in \u001b[0;36m_from_pretrained\u001b[0;34m(cls, resolved_vocab_files, pretrained_model_name_or_path, init_configuration, use_auth_token, cache_dir, *init_inputs, **kwargs)\u001b[0m\n\u001b[1;32m   1913\u001b[0m         \u001b[0;31m# Instantiate tokenizer.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1914\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1915\u001b[0;31m             \u001b[0mtokenizer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcls\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minit_inputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0minit_kwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1916\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mOSError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1917\u001b[0m             raise OSError(\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/transformers/models/albert/tokenization_albert_fast.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, vocab_file, tokenizer_file, do_lower_case, remove_space, keep_accents, bos_token, eos_token, unk_token, sep_token, pad_token, cls_token, mask_token, **kwargs)\u001b[0m\n\u001b[1;32m    159\u001b[0m             \u001b[0mcls_token\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcls_token\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    160\u001b[0m             \u001b[0mmask_token\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmask_token\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 161\u001b[0;31m             \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    162\u001b[0m         )\n\u001b[1;32m    163\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/transformers/tokenization_utils_fast.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    110\u001b[0m         \u001b[0;32melif\u001b[0m \u001b[0mslow_tokenizer\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    111\u001b[0m             \u001b[0;31m# We need to convert a slow tokenizer to build the backend\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 112\u001b[0;31m             \u001b[0mfast_tokenizer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mconvert_slow_tokenizer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mslow_tokenizer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    113\u001b[0m         \u001b[0;32melif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mslow_tokenizer_class\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    114\u001b[0m             \u001b[0;31m# We need to create and convert a slow tokenizer to build the backend\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/transformers/convert_slow_tokenizer.py\u001b[0m in \u001b[0;36mconvert_slow_tokenizer\u001b[0;34m(transformer_tokenizer)\u001b[0m\n\u001b[1;32m   1031\u001b[0m     \u001b[0mconverter_class\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mSLOW_TO_FAST_CONVERTERS\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mtokenizer_class_name\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1032\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1033\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mconverter_class\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtransformer_tokenizer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconverted\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/transformers/convert_slow_tokenizer.py\u001b[0m in \u001b[0;36mconverted\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    477\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    478\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mconverted\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mTokenizer\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 479\u001b[0;31m         \u001b[0mtokenizer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtokenizer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mproto\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    480\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    481\u001b[0m         \u001b[0;31m# Tokenizer assemble\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/transformers/convert_slow_tokenizer.py\u001b[0m in \u001b[0;36mtokenizer\u001b[0;34m(self, proto)\u001b[0m\n\u001b[1;32m    442\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    443\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mmodel_type\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 444\u001b[0;31m             \u001b[0mtokenizer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mTokenizer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mUnigram\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvocab\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0munk_id\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    445\u001b[0m         \u001b[0;32melif\u001b[0m \u001b[0mmodel_type\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m2\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    446\u001b[0m             \u001b[0m_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmerges\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mSentencePieceExtractor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moriginal_tokenizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvocab_file\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mextract\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mKeyboardInterrupt\u001b[0m: "]}],"source":["tokenizer = t.AutoTokenizer.from_pretrained('ai4bharat/indic-bert')"]},{"cell_type":"code","source":["# Encode our concatenated data\n","encoded_sent = [tokenizer.encode(sent, add_special_tokens=True) for sent in df.word.values]\n","\n","# Find the maximum length\n","max_len = max([len(sent) for sent in encoded_sent])\n","print('Max length: ', max_len)"],"metadata":{"id":"LHiJn0R8FUyR"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# Specify `MAX_LEN`\n","MAX_LEN = 30"],"metadata":{"id":"wxSEy2CjGWVl"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["from sklearn.model_selection import train_test_split\n","\n","df.iob_tag = pd.factorize(df.iob_tag)[0]\n","\n","X = df.word.values\n","y = df.iob_tag.values\n","\n","X_train, X_val, y_train, y_val = train_test_split(X, y, test_size=0.1, random_state=27)"],"metadata":{"id":"Uc_rJJdFHOBJ"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["def to_tensor(x):\n","  ans = torch.tensor(x)\n","  return ans"],"metadata":{"id":"G9re2q1DHPx4"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["input_ids = []\n","attention_mask = []\n","for sent in X_train:\n","    encoded_sent = tokenizer.encode_plus(text=sent,add_special_tokens=True,max_length=MAX_LEN,pad_to_max_length=True,return_attention_mask=True)\n","    input_ids.append(encoded_sent.get('input_ids'))\n","    attention_mask.append(encoded_sent.get('attention_mask'))\n","train_masks = to_tensor(attention_mask)\n","train_inputs = to_tensor(input_ids)"],"metadata":{"id":"T6NLCU9en0j8"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["input_ids = []\n","attention_mask = []\n","\n","for sent in X_val:\n","    encoded_sent = tokenizer.encode_plus(text=sent,add_special_tokens=True,max_length=MAX_LEN,pad_to_max_length=True,return_attention_mask=True)\n","    input_ids.append(encoded_sent.get('input_ids'))\n","    attention_mask.append(encoded_sent.get('attention_mask'))\n","\n","val_inputs = to_tensor(input_ids) \n","val_masks = to_tensor(attention_mask)"],"metadata":{"id":"Hrw3JmwtozlQ"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["## Import test data into test_df (dataframe)"],"metadata":{"id":"vxFtxZ-itMRv"}},{"cell_type":"code","source":["test_df = pd.read_csv(\"drive/MyDrive/hi_dev.conll\", sep = '_ _', names = ['word', 'iob_tag'])\n"],"metadata":{"id":"S3n-6FWRFUtS"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["## Preprocess test_df "],"metadata":{"id":"YtOCIJDDtTiO"}},{"cell_type":"code","source":["test_df = preprocess_train(test_df)\n","test_df.iob_tag = pd.factorize(test_df.iob_tag)[0]"],"metadata":{"id":"28pV3dEVSM8o"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["from torch.utils.data import TensorDataset, DataLoader, RandomSampler, SequentialSampler\n","# For fine-tuning BERT, the authors recommend a batch size of 16 or 32.\n","batch_size = 32\n","# Convert other data types to torch.Tensor\n","train_labels = torch.tensor(y_train)\n","val_labels = torch.tensor(y_val)\n","# Create the DataLoader for our validation set\n","val_data = TensorDataset(val_inputs, val_masks, val_labels)\n","val_sampler = SequentialSampler(val_data)\n","val_dataloader = DataLoader(val_data, sampler=val_sampler, batch_size=batch_size)\n","# Create the DataLoader for our training set\n","train_data = TensorDataset(train_inputs, train_masks, train_labels)\n","train_sampler = RandomSampler(train_data)\n","train_dataloader = DataLoader(train_data, sampler=train_sampler, batch_size=batch_size)"],"metadata":{"id":"vHjIFG7kFUq9"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["import torch\n","import torch.nn as nn\n","from transformers import BertModel\n","\n","# Create the BertClassfier class\n","class BertClassifier(nn.Module):\n","    \"\"\"Bert Model for Classification Tasks.\n","    \"\"\"\n","    def __init__(self, freeze_bert=True):\n","        \"\"\"\n","        @param    bert: a BertModel object\n","        @param    classifier: a torch.nn.Module classifier\n","        @param    freeze_bert (bool): Set `False` to fine-tune the BERT model\n","        \"\"\"\n","        super(BertClassifier, self).__init__()\n","        # Specify hidden size of BERT, hidden size of our classifier, and number of labels\n","\n","        # Instantiate BERT model\n","        self.bert = AutoModel.from_pretrained('ai4bharat/indic-bert')\n","\n","        # Instantiate an one-layer feed-forward classifier\n","        self.classifier = nn.Sequential(\n","            nn.Dropout(0.2),\n","            nn.Linear(768, 128),\n","            nn.ReLU(),\n","            nn.Linear(128, 64),\n","            nn.Dropout(0.2),\n","            nn.ReLU(),\n","            #nn.Dropout(0.5),\n","            nn.Linear(64, 13),\n","            nn.LogSoftmax(dim=1)\n","        )\n","\n","        # Freeze the BERT model\n","        if freeze_bert:\n","            for param in self.bert.parameters():\n","                param.requires_grad = False\n","        \n","    def forward(self, input_ids, attention_mask):\n","        # Feed input to BERT\n","        outputs = self.bert(input_ids, attention_mask)\n","        \n","        # Extract the last hidden state of the token `[CLS]` for classification task\n","        last_hidden_state_cls = outputs[0][:, 0, :]\n","\n","        # Feed input to classifier to compute logits\n","        logits = self.classifier(last_hidden_state_cls)\n","\n","        return logits"],"metadata":{"id":"lpsBn33j1yZ7"},"execution_count":null,"outputs":[]},{"cell_type":"code","execution_count":null,"metadata":{"id":"q4S8a_oGKrJP"},"outputs":[],"source":["# pass the pre-trained BERT to our define architecture\n","model = BertClassifier()\n","\n","# push the model to GPU\n","model = model.to(device)"]},{"cell_type":"markdown","source":[""],"metadata":{"id":"beYgeYhF_k1R"}},{"cell_type":"code","source":["from transformers.optimization import Adafactor, AdafactorSchedule\n"],"metadata":{"id":"86gToOIm_oRm"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["optimizer = Adafactor(model.parameters(), scale_parameter=False, relative_step=False, warmup_init=False, lr=1e-4)\n"],"metadata":{"id":"-_ZaaoMMXbmo"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["loss_fn = nn.CrossEntropyLoss()"],"metadata":{"id":"iflLjUa18SRi"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":[""],"metadata":{"id":"ou1ij8F_BDda"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["import random\n","import time\n","\n","# Specify loss function\n","loss_fn = nn.CrossEntropyLoss()\n","\n","def set_seed(seed_value=0):\n","    random.seed(seed_value)\n","    np.random.seed(seed_value)\n","    torch.manual_seed(seed_value)\n","    torch.cuda.manual_seed_all(seed_value)\n","\n","def train(model, train_dataloader, val_dataloader=None, epochs=4, evaluation=False):\n","    print(\"Start training...\\n\")\n","    for epoch_i in range(epochs):\n","        print(f\"{'Epoch':^7} | {'Batch':^7} | {'Train Loss':^12} | {'Val Loss':^10} | {'Val Acc':^9} | {'Elapsed':^9}\")\n","        print(\"-\"*70)\n","\n","        # Measure the elapsed time of each epoch\n","        t0_epoch, t0_batch = time.time(), time.time()\n","\n","        # Reset tracking variables at the beginning of each epoch\n","        total_loss, batch_loss, batch_counts = 0, 0, 0\n","\n","        # Put the model into the training mode\n","        model.train()\n","\n","        # For each batch of training data...\n","        for step, batch in enumerate(train_dataloader):\n","            batch_counts +=1\n","            # Load batch to GPU\n","            b_input_ids, b_attn_mask, b_labels = tuple(t.to(device) for t in batch)\n","\n","            # Zero out any previously calculated gradients\n","            model.zero_grad()\n","\n","            # Perform a forward pass. This will return logits.\n","            logits = model(b_input_ids, b_attn_mask)\n","\n","            # Compute loss and accumulate the loss values\n","            loss = loss_fn(logits, b_labels)\n","            batch_loss += loss.item()\n","            total_loss += loss.item()\n","\n","            # Perform a backward pass to calculate gradients\n","            loss.backward()\n","\n","            # Clip the norm of the gradients to 1.0 to prevent \"exploding gradients\"\n","            torch.nn.utils.clip_grad_norm_(model.parameters(), 1.0)\n","\n","            # Update parameters and the learning rate\n","            optimizer.step()\n","\n","            # Print the loss values and time elapsed for every 20 batches\n","            if (step % 100 == 0 and step != 0) or (step == len(train_dataloader) - 1):\n","                # Calculate time elapsed for 20 batches\n","                time_elapsed = time.time() - t0_batch\n","\n","                # Print training results\n","                print(f\"{epoch_i + 1:^7} | {step:^7} | {batch_loss / batch_counts:^12.6f} | {'-':^10} | {'-':^9} | {time_elapsed:^9.2f}\")\n","\n","                # Reset batch tracking variables\n","                batch_loss, batch_counts = 0, 0\n","                t0_batch = time.time()\n","\n","        # Calculate the average loss over the entire training data\n","        avg_train_loss = total_loss / len(train_dataloader)\n","\n","        print(\"-\"*70)\n","        if evaluation == True:\n","            # After the completion of each training epoch, measure the model's performance\n","            # on our validation set.\n","            val_loss, val_accuracy = evaluate(model, val_dataloader)\n","\n","            # Print performance over the entire training data\n","            time_elapsed = time.time() - t0_epoch\n","            \n","            print(f\"{epoch_i + 1:^7} | {'-':^7} | {avg_train_loss:^12.6f} | {val_loss:^10.6f} | {val_accuracy:^9.2f} | {time_elapsed:^9.2f}\")\n","            print(\"-\"*70)\n","        print(\"\\n\")\n","    \n","    print(\"Training complete!\")\n","\n","\n","def evaluate(model, val_dataloader):\n","    # Put the model into the evaluation mode. The dropout layers are disabled during\n","    # the test time.\n","    model.eval()\n","\n","    # Tracking variables\n","    val_score = []\n","    val_loss = []\n","\n","    # For each batch in our validation set...\n","    for batch in val_dataloader:\n","        # Load batch to GPU\n","        b_input_ids, b_attn_mask, b_labels = tuple(t.to(device) for t in batch)\n","\n","        # Compute logits\n","        with torch.no_grad():\n","            logits = model(b_input_ids, b_attn_mask)\n","\n","        # Compute loss\n","        loss = loss_fn(logits, b_labels)\n","        val_loss.append(loss.item())\n","\n","        # Get the predictions\n","        preds = torch.argmax(logits, dim=1).flatten()\n","\n","        # Calculate the accuracy rate\n","        score = f1_score(preds.cpu().numpy(), b_labels.cpu().numpy(), zero_division=1, average = 'weighted')\n","        val_score.append(score)\n","\n","    # Compute the average accuracy and loss over the validation set.\n","    val_loss = np.mean(val_loss)\n","    val_accuracy = np.mean(val_score)\n","\n","    return val_loss, val_accuracy"],"metadata":{"id":"qfMudehDyGrD"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["import tensorflow\n","tensorflow.random.set_seed(0)\n","from sklearn.metrics import f1_score\n","from sklearn.metrics import accuracy_score\n","\n","train(model, train_dataloader, val_dataloader, epochs=2, evaluation=True)\n"],"metadata":{"id":"dlP4cYAQyGot"},"execution_count":null,"outputs":[]},{"cell_type":"code","execution_count":null,"metadata":{"id":"BtOtsTOa_i4w"},"outputs":[],"source":["import torch.nn.functional as F\n","\n","\n","\n","def bert_predict(model, test_dataloader):\n","    test_score = []\n","    model.eval()\n","    for batch in test_dataloader:\n","        b_input_ids, b_attn_mask, b_labels = tuple(t.to(device) for t in batch)\n","\n","        with torch.no_grad():\n","            logits = model(b_input_ids, b_attn_mask)\n","        \n","        preds = torch.argmax(logits, dim=1).flatten()\n","\n","        score = f1_score(preds.cpu(), b_labels.cpu(),  average = 'weighted')\n","\n","        test_score.append(score)\n","\n","    return np.mean(test_score)"]},{"cell_type":"code","source":["# test_inputs, test_masks = preprocessing_for_bert(test_df.word)\n","input_ids = []\n","attention_masks = []\n","\n","for sent in test_df.word:\n","  encoded_sent = tokenizer.encode_plus(text=sent,add_special_tokens=True,max_length=MAX_LEN,pad_to_max_length=True,return_attention_mask=True)\n","\n","  input_ids.append(encoded_sent.get('input_ids'))\n","  attention_masks.append(encoded_sent.get('attention_mask'))\n","\n","    # Convert lists to tensors\n","input_ids = torch.tensor(input_ids)\n","attention_masks = torch.tensor(attention_masks)\n","\n","test_inputs  = input_ids \n","test_masks = attention_masks"],"metadata":{"id":"mLc_OevYpbzM"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["\n","test_labels = torch.tensor(test_df.iob_tag)\n","\n","# Create the DataLoader for our test set\n","test_dataset = TensorDataset(test_inputs, test_masks, test_labels)\n","test_sampler = SequentialSampler(test_dataset)\n","test_dataloader = DataLoader(test_dataset, sampler=test_sampler, batch_size=batch_size)"],"metadata":{"id":"k4Gra1WqPA6G"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":[""],"metadata":{"id":"EDGHcdhLiL9u"},"execution_count":null,"outputs":[]}],"metadata":{"accelerator":"GPU","colab":{"collapsed_sections":[],"name":"Q2.ipynb","provenance":[]},"interpreter":{"hash":"66e3d188d02a210bab72f20c506ffac958ef9b0a7153119813a4060f203dc33d"},"kernelspec":{"display_name":"Python 3.9.7 ('base')","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.9.7"},"widgets":{"application/vnd.jupyter.widget-state+json":{"3bbc3477d289400d919ba3049ba9dc63":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_b2fe9ed77ebb48e6beac70d7f29507d2","IPY_MODEL_8d4f50b54f9142ddb9596519cb0acb15","IPY_MODEL_8f315c9831f944f3a6e275e204f81bd9"],"layout":"IPY_MODEL_a11bbcbf9dd0457799e3b8fc419bc03c"}},"b2fe9ed77ebb48e6beac70d7f29507d2":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_4be9926eae1740c6a60b589b49303927","placeholder":"​","style":"IPY_MODEL_e24d75c7e7c048b88498cb583cd511c0","value":"Downloading: 100%"}},"8d4f50b54f9142ddb9596519cb0acb15":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_8b4510d705794fc39927d720ebf423d8","max":507,"min":0,"orientation":"horizontal","style":"IPY_MODEL_f0dd4182cb214191a6c88144c7e7945e","value":507}},"8f315c9831f944f3a6e275e204f81bd9":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_ec5eb972a4a24c76919ccc3ff5861896","placeholder":"​","style":"IPY_MODEL_5cdde97f31e5433f856b0d6b189e4be2","value":" 507/507 [00:00&lt;00:00, 3.21kB/s]"}},"a11bbcbf9dd0457799e3b8fc419bc03c":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"4be9926eae1740c6a60b589b49303927":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"e24d75c7e7c048b88498cb583cd511c0":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"8b4510d705794fc39927d720ebf423d8":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"f0dd4182cb214191a6c88144c7e7945e":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"ec5eb972a4a24c76919ccc3ff5861896":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"5cdde97f31e5433f856b0d6b189e4be2":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"f9b986f2adf84a51b6d5160f17245727":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_6e20a482debf4e81b66a3b9694d013f1","IPY_MODEL_c7e97513a7874c1b9618d2758311ce8c","IPY_MODEL_cbce898eabfe49b2af0b59052f01f7c9"],"layout":"IPY_MODEL_2c11a22d099d434cb99c4ef978ea3a71"}},"6e20a482debf4e81b66a3b9694d013f1":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_3de465594e5c47f9ad3a452e574e3e27","placeholder":"​","style":"IPY_MODEL_367d4b5c974c4931b44d7d94aa35b109","value":"Downloading: 100%"}},"c7e97513a7874c1b9618d2758311ce8c":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_3f2ff6b220994ebcaf899f462d23ea9b","max":5646064,"min":0,"orientation":"horizontal","style":"IPY_MODEL_8db8002e2c6a4d198dfadb81d6c371b1","value":5646064}},"cbce898eabfe49b2af0b59052f01f7c9":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_4833c1f06a2848f7a95f3b861f3f2a1e","placeholder":"​","style":"IPY_MODEL_c20623f149da446a9359633925ca9ef9","value":" 5.38M/5.38M [00:00&lt;00:00, 8.99MB/s]"}},"2c11a22d099d434cb99c4ef978ea3a71":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"3de465594e5c47f9ad3a452e574e3e27":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"367d4b5c974c4931b44d7d94aa35b109":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"3f2ff6b220994ebcaf899f462d23ea9b":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"8db8002e2c6a4d198dfadb81d6c371b1":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"4833c1f06a2848f7a95f3b861f3f2a1e":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"c20623f149da446a9359633925ca9ef9":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}}}}},"nbformat":4,"nbformat_minor":0}